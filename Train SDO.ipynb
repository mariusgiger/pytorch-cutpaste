{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9447691",
      "metadata": {
        "id": "c9447691"
      },
      "source": [
        "## CutPaste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "TDWBbAn0Ebh5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDWBbAn0Ebh5",
        "outputId": "83c8e25e-c4de-4cc8-d988-8d0732f20840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-cutpaste'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 217 (delta 102), reused 192 (delta 80), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (217/217), 838.29 KiB | 5.17 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b master 'https://github.com/mariusgiger/pytorch-cutpaste.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aEXJdgLSEvgn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEXJdgLSEvgn",
        "outputId": "7f954f6c-a832-43fa-ca71-5e3472853b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-cutpaste\n"
          ]
        }
      ],
      "source": [
        "cd pytorch-cutpaste/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrc6_OGZBG6e",
        "outputId": "da40ba41-ec86-47a2-bf34-1c30465c8c5a"
      },
      "id": "vrc6_OGZBG6e",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpA63QkDGEB",
        "outputId": "8f6f855d-c451-4b80-8e07-657fcba75bdb"
      },
      "id": "3XpA63QkDGEB",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/mariusgiger/pytorch-cutpaste\n",
            "   57a74c2..0306483  master     -> origin/master\n",
            "Updating 57a74c2..0306483\n",
            "Fast-forward\n",
            " run_training_sdo.py | 7 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 6 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R909FCyrI7MM",
        "outputId": "4395b8ec-b880-46d3-99a7-dbf437c59ab5"
      },
      "id": "R909FCyrI7MM",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 49.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log in to your W&B account\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "wvwDGh7dI-k-",
        "outputId": "28f802c1-6eaa-4155-8f81-41600692b27a"
      },
      "id": "wvwDGh7dI-k-",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "6b6d6899",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b6d6899",
        "outputId": "8d51bc01-c46c-496c-c5de-ab635676cc03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=64, cuda='True', data_dir='../drive/MyDrive/Master/Data/aia_171_2018_b_256', epochs=1024, freeze_resnet=256, head_layer=2, lr=0.03, model_dir='models', optim='sgd', pretrained=True, test_epochs=10, variant='normal', wave_length='171', workers=8)\n",
            "using device: cuda\n",
            "training AIA 171\n",
            "loading images\n",
            "loaded 640 images\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "  0% 0/1024 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 1024/1024 [19:54<00:00,  1.17s/it]\n"
          ]
        }
      ],
      "source": [
        "!python run_training_sdo.py --wave_length=171 --model_dir models --cuda True --head_layer 2 --data_dir ../drive/MyDrive/Master/Data/aia_171_2018_b_256 --epochs 1024 --freeze_resnet 256 --variant normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff402ae2",
      "metadata": {
        "id": "ff402ae2",
        "outputId": "42eedce0-1678-459e-dfff-5d9acd495c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.3.5.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 631 kB/s eta 0:00:01\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting opencv-python>=4.1torch>=1.4\n",
            "  Downloading opencv_python-4.5.4.58-cp39-cp39-macosx_10_15_x86_64.whl (45.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.5 MB 1.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.42 in ./.venv/lib/python3.9/site-packages (from grad-cam) (4.62.3)\n",
            "Requirement already satisfied: torchvision>=0.5 in ./.venv/lib/python3.9/site-packages (from grad-cam) (0.10.1)\n",
            "Collecting ttach>=0.0.3\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in ./.venv/lib/python3.9/site-packages (from opencv-python>=4.1torch>=1.4->grad-cam) (1.21.2)\n",
            "Requirement already satisfied: torch==1.9.1 in ./.venv/lib/python3.9/site-packages (from torchvision>=0.5->grad-cam) (1.9.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in ./.venv/lib/python3.9/site-packages (from torchvision>=0.5->grad-cam) (8.3.2)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from torch==1.9.1->torchvision>=0.5->grad-cam) (3.10.0.2)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for grad-cam: filename=grad_cam-1.3.5-py3-none-any.whl size=22419 sha256=13b0d0a14d1c1bc236aa32d90ca238aecebf08f835a3fe413b3838bbecbb1143\n",
            "  Stored in directory: /Users/mariusgiger/Library/Caches/pip/wheels/e6/a2/73/564b397e26e7064d784fd0429cc9b93921133a53d1ecb9fc0d\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, opencv-python, grad-cam\n",
            "Successfully installed grad-cam-1.3.5 opencv-python-4.5.4.58 ttach-0.0.3\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the '/Users/mariusgiger/repos/master/pytorch-cutpaste/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam==1.3.5"
      ],
      "metadata": {
        "id": "6W3i44QZKI8h",
        "outputId": "e781a1ec-c831-474e-ba89-1108b6c43b1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6W3i44QZKI8h",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam==1.3.5\n",
            "  Downloading grad-cam-1.3.5.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ttach>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.5) (0.0.3)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.5) (4.62.3)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.5) (0.11.1+cu111)\n",
            "Requirement already satisfied: opencv-python>=4.1torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from grad-cam==1.3.5) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1torch>=1.4->grad-cam==1.3.5) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->grad-cam==1.3.5) (7.1.2)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->grad-cam==1.3.5) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision>=0.5->grad-cam==1.3.5) (3.10.0.2)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.3.5-py3-none-any.whl size=22419 sha256=0d973e50a9238be01ee3a9962bb756cf4bc98f1f8a9bec4b00383c2039432a97\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/d1/a6/41cb46183c56fe9e78ba80781ca35c3bc2728406b694fb7a13\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: grad-cam\n",
            "  Attempting uninstall: grad-cam\n",
            "    Found existing installation: grad-cam 1.3.7\n",
            "    Uninstalling grad-cam-1.3.7:\n",
            "      Successfully uninstalled grad-cam-1.3.7\n",
            "Successfully installed grad-cam-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 cam.py --model_path /content/pytorch-cutpaste/models/model-171-2022-01-11_17_42_56.tch --dataset SDO --image-path \"/content/drive/MyDrive/Master/Data/aia_171_2018_b_256/test/2012-02-21T000000__171.jpeg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCiBioKSHixE",
        "outputId": "ccb8925d-cf5c-4fa1-dc87-e997edc89769"
      },
      "id": "mCiBioKSHixE",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU for computation\n",
            "loading model /content/pytorch-cutpaste/models/model-171-2022-01-11_17_42_56.tch\n",
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8b9a93e",
      "metadata": {
        "id": "c8b9a93e"
      },
      "source": [
        "## Links\n",
        "\n",
        "- https://www.mvtec.com/company/research/datasets/mvtec-ad\n",
        "- https://github.com/Runinho/pytorch-cutpaste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8d358c6e",
      "metadata": {
        "id": "8d358c6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73efb4d-5b72-44bc-ccb1-cd2695f28e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-cutpaste\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JrhCzHmXOFpT"
      },
      "id": "JrhCzHmXOFpT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (cutpaste)",
      "language": "python",
      "name": "cutpaste"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}